model:
  name: "llama3:8b"  # adjusted for local hardware  # Change to your preferred Ollama model
  temperature: 0.7
  max_tokens: 2048

bicameral:
  tick_interval: 0.5  # seconds between consciousness ticks
  tick_threshold:
    entropy: 0.6  # uncertainty threshold
    conflict: 0.5  # inter-brain conflict threshold
    novelty: 0.7  # pattern novelty threshold
  
  left_brain:
    name: "PatternRecognition"
    focus: "stability"
    behaviors:
      - "compress_patterns"
      - "classify"
      - "replicate_known"
      - "validate_consistency"
    
  right_brain:
    name: "PatternMutation"
    focus: "exploration"
    behaviors:
      - "detect_anomalies"
      - "mutate_patterns"
      - "generate_variants"
      - "explore_novel"

rag:
  enabled: true
  chunk_size: 512
  chunk_overlap: 50
  top_k: 5
  retrieval_mode: "agentic"  # agentic or single-pass
  max_iterations: 5

vector_store:
  type: "chroma"  # chroma or faiss
  persist_directory: "./data/vector_store"
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"

mcp:
  # Enable MCP to allow the bicameral mind to call external tools via the
  # Model Context Protocol. When enabled, the system will connect to the
  # configured servers and discover available tools.
  enabled: true

  # Connection settings
  connection_timeout: 30  # seconds
  tool_timeout: 60  # seconds per tool execution
  max_retries: 3  # connection retry attempts

  # Tool filtering
  allowed_tools: []  # Empty list = allow all tools (except blocked)
  blocked_tools: []  # Tools to explicitly block (e.g., ["delete_all", "format_disk"])

  # Learning settings
  auto_learn: true  # Automatically learn from tool executions
  learn_on_success: true  # Learn from successful tool calls
  learn_on_failure: true  # Learn from failed tool calls

  # MCP Servers
  servers:
    # Filesystem tools
    - name: "filesystem"
      type: "stdio"
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "./data"]
      enabled: true

    # GitHub integration
    - name: "github"
      type: "stdio"
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-github"]
      env:
        GITHUB_PERSONAL_ACCESS_TOKEN: "${GITHUB_TOKEN}"
      enabled: false  # Requires GitHub token

    # Web search (Brave)
    - name: "brave_search"
      type: "stdio"
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-brave-search"]
      env:
        BRAVE_API_KEY: "${BRAVE_API_KEY}"
      enabled: false  # Requires Brave API key

    # Google Drive
    - name: "gdrive"
      type: "stdio"
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-gdrive"]
      enabled: false  # Requires OAuth setup

    # Slack
    - name: "slack"
      type: "stdio"
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-slack"]
      env:
        SLACK_BOT_TOKEN: "${SLACK_BOT_TOKEN}"
      enabled: false  # Requires Slack token

    # Custom API server (example)
    - name: "custom_api"
      type: "api"
      endpoint: "http://localhost:5000/mcp"
      enabled: false  # Configure endpoint as needed

memory:
  short_term_capacity: 20
  long_term_persistence: true
  consolidation_threshold: 10

logging:
  level: "INFO"
  file: "./logs/bicameral_mind.log"
